<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jaeseok Hwang">
<meta name="dcterms.date" content="2025-12-17">

<title>A Narrative of Statistics for the Social Scientist</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./01.binary_choice_to_normal.html" rel="next">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./index.html">Preface</a></li><li class="breadcrumb-item"><a href="./index.html"><span class="chapter-title">Overview</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">A Narrative of Statistics for the Social Scientist</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Preface</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Overview</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">The Classical Foundations</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01.binary_choice_to_normal.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">1. The Binary Choice to Normal Distribution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02.from_probability_to_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">From Probability to Likelihood</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-courtroom.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">03-courtroom.html</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-bending-the-line.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">04-bending-the-line.html</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">The Modern Complexity</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">05-regularization.html</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-bayesian.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">06-bayesian.html</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-time-space.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">07-time-space.html</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-trees-forests.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">08-trees-forests.html</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prob_dist_connect.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">From Binary Selection to the Bell Curve: Bernoulli → de Moivre → Laplace</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./index.html">Preface</a></li><li class="breadcrumb-item"><a href="./index.html"><span class="chapter-title">Overview</span></a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">A Narrative of Statistics for the Social Scientist</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jaeseok Hwang </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 17, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="preface-the-guidance-system" class="level1 unnumbered">
<h1 class="unnumbered">Preface: The Guidance System</h1>
<p>To be honest, I spent about ten years learning statistics the wrong way. As a social scientist with a background in Economics, I was trained to be a “consumer” of methods. I knew how to run the software and interpret the output, but I had a hard time grasping the intuition behind the machine. I often felt that my understanding had cracks in it—gaps where the logic should have been solid. For years, I struggled with the fundamental questions that define the “Producer” of research: Why are sample statistics so different from population parameters? Why do we carefully select an assumed distribution instead of just using the raw data? What is the actual difference between parametric and non-parametric approaches?</p>
<p>Like many social scientists, I had been consuming only the “surface” of statistics—the simple examples and the black-box tools—without ever seeing what lay beneath. I knew this feeling well because I had faced it before in my own field. During my undergraduate and Master’s studies in Economics, I was overwhelmed by the complex definitions, theorems, and math required to be an advanced user. But during the first two years of my Ph.D., I managed to break through that complex system. I forced myself to stop memorizing and start creating storylines that connected those isolated theorems into coherent narratives.</p>
<p>It felt like I had transferred my brain through a hidden gateway—like the platform in Harry Potter—and gradually, the chaos has turned into a system. Now, I want to use that same discipline to bridge the “holes and cracks” in my understanding of statistics. This book is a documentation of that journey. It is written for social scientists, or anyone unfamiliar with complex math, who want to look into the “beautiful mind of nerds” without getting lost in the equations. My goal is to use storylines and narratives to strip away the intimidating surface and look into the logic underneath.</p>
<p>We are going to treat statistics not as a set of rules, but as a series of solutions to specific problems.</p>
<section id="the-roadmap" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-roadmap">The Roadmap</h2>
</section>
</section>
<section id="part-i-the-classical-foundations" class="level1 unnumbered">
<h1 class="unnumbered">Part I: The Classical Foundations</h1>
<section id="the-binary-choice-from-dust-to-distributions" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-binary-choice-from-dust-to-distributions">1. The Binary Choice: From Dust to Distributions</h2>
<p><strong>The Narrative:</strong> We begin with the most primitive unit of information: the binary choice (Life vs.&nbsp;Death). We trace how repeating this jagged choice millions of times smooths it out into the “Classical Family” of distributions.</p>
<ul>
<li><strong>Models:</strong>
<ul>
<li><strong>Bernoulli &amp; Binomial:</strong> The origin (discrete trials).</li>
<li><strong>Normal (Gaussian):</strong> The destination (continuous limit).</li>
<li><strong>Poisson:</strong> The limit of rare events.</li>
<li><strong>Exponential &amp; Gamma:</strong> The modeling of waiting times.</li>
</ul></li>
<li><strong>Theory:</strong>
<ul>
<li><strong>Central Limit Theorem (CLT):</strong> Why sums tend toward Normality.</li>
<li><strong>Maximum Entropy:</strong> Why the Normal is the “most honest” assumption for a fixed variance.</li>
<li><strong>Law of Rare Events:</strong> The bridge from Binomial to Poisson.</li>
</ul></li>
<li><strong>Functions (The Math):</strong>
<ul>
<li><strong>PDFs/PMFs:</strong> The density formulas.</li>
<li><strong>Moment Generating Functions (MGF):</strong> <span class="math inline">\(M(t) = E[e^{tX}]\)</span> (The genetic code of distributions).</li>
<li><strong>Taylor Series Expansion:</strong> Used to prove how higher moments vanish in the limit.</li>
</ul></li>
</ul>
</section>
<section id="the-detective-likelihood-estimation" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-detective-likelihood-estimation">2. The Detective: Likelihood &amp; Estimation</h2>
<p><strong>The Narrative:</strong> We stop playing God (knowing parameters) and start playing Detective (guessing them from data). We discover that “Least Squares” is just a special case of Likelihood.</p>
<ul>
<li><strong>Models:</strong>
<ul>
<li><strong>Standard Normal Model:</strong> Estimating <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</li>
<li><strong>Linear Regression (OLS):</strong> Re-introduced as a Maximum Likelihood estimator.</li>
</ul></li>
<li><strong>Theory:</strong>
<ul>
<li><strong>The Likelihood Principle:</strong> All evidence is contained in the likelihood function.</li>
<li><strong>Maximum Likelihood Estimation (MLE):</strong> Finding parameters that maximize the probability of the observed data.</li>
</ul></li>
<li><strong>Functions (The Math):</strong>
<ul>
<li><strong>Likelihood Function:</strong> <span class="math inline">\(L(\theta | X) = \prod f(x_i; \theta)\)</span>.</li>
<li><strong>Log-Likelihood:</strong> <span class="math inline">\(\ell(\theta) = \sum \ln f(x_i; \theta)\)</span> (The optimization surface).</li>
<li><strong>Score Function:</strong> The derivative of the Log-Likelihood.</li>
</ul></li>
</ul>
</section>
<section id="the-courtroom-hypothesis-testing" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-courtroom-hypothesis-testing">3. The Courtroom: Hypothesis Testing</h2>
<p><strong>The Narrative:</strong> The Detective finds a suspect, but the Courtroom must check the evidence. We introduce the Skeptic (Null Hypothesis) and measure “Surprise” rather than “Truth.”</p>
<ul>
<li><strong>Models:</strong>
<ul>
<li><strong>Null Model (<span class="math inline">\(H_0\)</span>):</strong> The restricted model (e.g., <span class="math inline">\(\beta = 0\)</span>).</li>
<li><strong>Alternative Model (<span class="math inline">\(H_1\)</span>):</strong> The full model.</li>
</ul></li>
<li><strong>Theory:</strong>
<ul>
<li><strong>Null Hypothesis Significance Testing (NHST).</strong></li>
<li><strong>Type I &amp; II Errors:</strong> False Positives vs.&nbsp;False Negatives.</li>
<li><strong>Asymptotic Normality:</strong> Why test statistics often follow a <span class="math inline">\(\chi^2\)</span> distribution.</li>
</ul></li>
<li><strong>Functions (The Math):</strong>
<ul>
<li><strong>Wald Statistic:</strong> Horizontal distance from the null.</li>
<li><strong>Likelihood Ratio Statistic:</strong> Vertical distance (height difference) between models.</li>
<li><strong>Score Statistic:</strong> The slope of the likelihood at the null.</li>
</ul></li>
</ul>
</section>
<section id="bending-the-line-generalized-linear-models-glm" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="bending-the-line-generalized-linear-models-glm">4. Bending the Line: Generalized Linear Models (GLM)</h2>
<p><strong>The Narrative:</strong> Standard regression fails when the outcome is binary or a count (lines go to infinity). We use a “Link Function” to translate linear math into bounded probabilities.</p>
<ul>
<li><strong>Models:</strong>
<ul>
<li><strong>Logistic Regression:</strong> For binary outcomes.</li>
<li><strong>Poisson Regression:</strong> For count data.</li>
<li><strong>GLM Framework:</strong> The unifying theory.</li>
</ul></li>
<li><strong>Theory:</strong>
<ul>
<li><strong>The Link Function:</strong> Separating the systematic component from the random component.</li>
<li><strong>Odds &amp; Log-Odds:</strong> Interpreting probability on a linear scale.</li>
</ul></li>
<li><strong>Functions (The Math):</strong>
<ul>
<li><strong>Sigmoid (Logit) Function:</strong> <span class="math inline">\(p = 1 / (1 + e^{-z})\)</span>.</li>
<li><strong>Log Link:</strong> <span class="math inline">\(\ln(\lambda) = \beta X\)</span>.</li>
<li><strong>Deviance:</strong> The GLM version of “Residual Sum of Squares.”</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="part-ii-the-modern-complexity" class="level1 unnumbered">
<h1 class="unnumbered">Part II: The Modern Complexity</h1>
<section id="the-penalty-regularization" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-penalty-regularization">5. The Penalty: Regularization</h2>
<p><strong>The Narrative:</strong> The Detective gets overconfident and starts seeing conspiracies (Overfitting). We introduce a “Judge” who fines the model for using too many variables.</p>
<ul>
<li><strong>Models:</strong>
<ul>
<li><strong>Ridge Regression (<span class="math inline">\(L_2\)</span>):</strong> Shrinks parameters.</li>
<li><strong>Lasso Regression (<span class="math inline">\(L_1\)</span>):</strong> Selects variables (forces some to zero).</li>
<li><strong>Elastic Net:</strong> The hybrid approach.</li>
</ul></li>
<li><strong>Theory:</strong>
<ul>
<li><strong>Bias-Variance Trade-off:</strong> The fundamental conflict of learning.</li>
<li><strong>Overfitting:</strong> Memorizing noise vs.&nbsp;learning signal.</li>
</ul></li>
<li><strong>Functions (The Math):</strong>
<ul>
<li><strong>Lagrange Multipliers:</strong> Solving constrained optimization.</li>
<li><strong>The Penalty Term:</strong> Adding <span class="math inline">\(+\lambda \sum \beta^2\)</span> to the Loss Function.</li>
<li><strong>Norms:</strong> Euclidean (<span class="math inline">\(L_2\)</span>) vs.&nbsp;Manhattan (<span class="math inline">\(L_1\)</span>) distance.</li>
</ul></li>
</ul>
</section>
<section id="the-subjective-return-bayesian-inference" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-subjective-return-bayesian-inference">6. The Subjective Return: Bayesian Inference</h2>
<p><strong>The Narrative:</strong> We realize the “Penalty” was actually a “Prior Belief.” We shift from seeking one True Parameter to mapping the entire distribution of uncertainty.</p>
<ul>
<li><strong>Models:</strong>
<ul>
<li><strong>Bayesian Linear Regression.</strong></li>
<li><strong>Hierarchical/Multilevel Models:</strong> Handling grouped data.</li>
</ul></li>
<li><strong>Theory:</strong>
<ul>
<li><strong>Bayes’ Theorem:</strong> Updating beliefs with data.</li>
<li><strong>Priors:</strong> Informative vs.&nbsp;Flat priors.</li>
<li><strong>Conjugacy:</strong> Mathematical compatibility between Prior and Likelihood.</li>
</ul></li>
<li><strong>Functions (The Math):</strong>
<ul>
<li><strong>Posterior Formulation:</strong> <span class="math inline">\(P(\theta|X) \propto P(X|\theta) \cdot P(\theta)\)</span>.</li>
<li><strong>MCMC (Markov Chain Monte Carlo):</strong> The simulation engine for complex posteriors.</li>
</ul></li>
</ul>
</section>
<section id="the-invisible-thread-time-series-spatial-analysis" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-invisible-thread-time-series-spatial-analysis">7. The Invisible Thread: Time Series &amp; Spatial Analysis</h2>
<p><strong>The Narrative:</strong> We stop assuming data points are independent islands. We acknowledge that today is haunted by yesterday (Time) and location shapes destiny (Space).</p>
<ul>
<li><strong>Models:</strong>
<ul>
<li><strong>ARIMA:</strong> Modeling memory in time.</li>
<li><strong>SAR / SEM:</strong> Spatial Autoregressive &amp; Spatial Error models.</li>
<li><strong>Gaussian Processes:</strong> The ultimate model of proximity.</li>
</ul></li>
<li><strong>Theory:</strong>
<ul>
<li><strong>Stationarity:</strong> The assumption that rules don’t change over time.</li>
<li><strong>Autocorrelation:</strong> Correlation of a variable with itself.</li>
<li><strong>Spatial Weights (<span class="math inline">\(W\)</span>):</strong> Defining the neighborhood.</li>
</ul></li>
<li><strong>Functions (The Math):</strong>
<ul>
<li><strong>Covariance Matrix (<span class="math inline">\(\Sigma\)</span>):</strong> Moving from Diagonal (independent) to Dense (correlated).</li>
<li><strong>ACF / PACF:</strong> Measuring the “echo” of the past.</li>
</ul></li>
</ul>
</section>
<section id="the-broken-mirror-trees-forests" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-broken-mirror-trees-forests">8. The Broken Mirror: Trees &amp; Forests</h2>
<p><strong>The Narrative:</strong> When the world is too fractured for smooth curves, we break it into shards. We use Decision Trees to split logic and Ensembles (Forests) to stabilize the result.</p>
<ul>
<li><strong>Models:</strong>
<ul>
<li><strong>CART (Decision Trees):</strong> The single shard.</li>
<li><strong>Random Forest:</strong> The Wisdom of Crowds (Bagging).</li>
<li><strong>Gradient Boosting (XGBoost):</strong> The Learning Student (Boosting).</li>
</ul></li>
<li><strong>Theory:</strong>
<ul>
<li><strong>Recursive Partitioning:</strong> Splitting data into homogenous groups.</li>
<li><strong>Ensemble Learning:</strong> Reducing Variance (Bagging) vs.&nbsp;Reducing Bias (Boosting).</li>
<li><strong>Gradient Descent in Function Space:</strong> Optimizing predictions step-by-step.</li>
</ul></li>
<li><strong>Functions (The Math):</strong>
<ul>
<li><strong>Gini Impurity / Entropy:</strong> Metrics for “purity” in a split.</li>
<li><strong>Information Gain:</strong> The reduction in entropy.</li>
</ul></li>
</ul>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
  </div>
  <div class="nav-page nav-page-next">
      <a href="./01.binary_choice_to_normal.html" class="pagination-link" aria-label="1. The Binary Choice to Normal Distribution">
        <span class="nav-page-text"><span class="chapter-title">1. The Binary Choice to Normal Distribution</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Overview" </span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Jaeseok Hwang"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2025-12-17"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: false # No table of contents needed for the cover page</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu"># Preface: The Guidance System {-}</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>To be honest, I spent about ten years learning statistics the wrong way. As a social scientist with a background in Economics, I was trained to be a "consumer" of methods. I knew how to run the software and interpret the output, but I had a hard time grasping the intuition behind the machine. I often felt that my understanding had cracks in it—gaps where the logic should have been solid. For years, I struggled with the fundamental questions that define the "Producer" of research: Why are sample statistics so different from population parameters? Why do we carefully select an assumed distribution instead of just using the raw data? What is the actual difference between parametric and non-parametric approaches? </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>Like many social scientists, I had been consuming only the "surface" of statistics—the simple examples and the black-box tools—without ever seeing what lay beneath. I knew this feeling well because I had faced it before in my own field. During my undergraduate and Master's studies in Economics, I was overwhelmed by the complex definitions, theorems, and math required to be an advanced user. But during the first two years of my Ph.D., I managed to break through that complex system. I forced myself to stop memorizing and start creating storylines that connected those isolated theorems into coherent narratives.</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>It felt like I had transferred my brain through a hidden gateway—like the platform in Harry Potter—and gradually, the chaos has turned into a system. Now, I want to use that same discipline to bridge the "holes and cracks" in my understanding of statistics. This book is a documentation of that journey. It is written for social scientists, or anyone unfamiliar with complex math, who want to look into the "beautiful mind of nerds" without getting lost in the equations. My goal is to use storylines and narratives to strip away the intimidating surface and look into the logic underneath.</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>We are going to treat statistics not as a set of rules, but as a series of solutions to specific problems.</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Roadmap {-}</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="fu"># Part I: The Classical Foundations {-}</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="fu">## 1. The Binary Choice: From Dust to Distributions {-}</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>**The Narrative:** We begin with the most primitive unit of information: the binary choice (Life vs. Death). We trace how repeating this jagged choice millions of times smooths it out into the "Classical Family" of distributions.</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Models:**</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Bernoulli &amp; Binomial:** The origin (discrete trials).</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Normal (Gaussian):** The destination (continuous limit).</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Poisson:** The limit of rare events.</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Exponential &amp; Gamma:** The modeling of waiting times.</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Theory:**</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Central Limit Theorem (CLT):** Why sums tend toward Normality.</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Maximum Entropy:** Why the Normal is the "most honest" assumption for a fixed variance.</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Law of Rare Events:** The bridge from Binomial to Poisson.</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Functions (The Math):**</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**PDFs/PMFs:** The density formulas.</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Moment Generating Functions (MGF):** $M(t) = E<span class="co">[</span><span class="ot">e^{tX}</span><span class="co">]</span>$ (The genetic code of distributions).</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Taylor Series Expansion:** Used to prove how higher moments vanish in the limit.</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2. The Detective: Likelihood &amp; Estimation {-}</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>**The Narrative:** We stop playing God (knowing parameters) and start playing Detective (guessing them from data). We discover that "Least Squares" is just a special case of Likelihood.</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Models:**</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Standard Normal Model:** Estimating $\mu$ and $\sigma$.</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Linear Regression (OLS):** Re-introduced as a Maximum Likelihood estimator.</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Theory:**</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**The Likelihood Principle:** All evidence is contained in the likelihood function.</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Maximum Likelihood Estimation (MLE):** Finding parameters that maximize the probability of the observed data.</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Functions (The Math):**</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Likelihood Function:** $L(\theta | X) = \prod f(x_i; \theta)$.</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Log-Likelihood:** $\ell(\theta) = \sum \ln f(x_i; \theta)$ (The optimization surface).</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Score Function:** The derivative of the Log-Likelihood.</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="fu">## 3. The Courtroom: Hypothesis Testing {-}</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>**The Narrative:** The Detective finds a suspect, but the Courtroom must check the evidence. We introduce the Skeptic (Null Hypothesis) and measure "Surprise" rather than "Truth."</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Models:**</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Null Model ($H_0$):** The restricted model (e.g., $\beta = 0$).</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Alternative Model ($H_1$):** The full model.</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Theory:**</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Null Hypothesis Significance Testing (NHST).**</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Type I &amp; II Errors:** False Positives vs. False Negatives.</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Asymptotic Normality:** Why test statistics often follow a $\chi^2$ distribution.</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Functions (The Math):**</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Wald Statistic:** Horizontal distance from the null.</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Likelihood Ratio Statistic:** Vertical distance (height difference) between models.</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Score Statistic:** The slope of the likelihood at the null.</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="fu">## 4. Bending the Line: Generalized Linear Models (GLM) {-}</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>**The Narrative:** Standard regression fails when the outcome is binary or a count (lines go to infinity). We use a "Link Function" to translate linear math into bounded probabilities.</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Models:**</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Logistic Regression:** For binary outcomes.</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Poisson Regression:** For count data.</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**GLM Framework:** The unifying theory.</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Theory:**</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**The Link Function:** Separating the systematic component from the random component.</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Odds &amp; Log-Odds:** Interpreting probability on a linear scale.</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Functions (The Math):**</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Sigmoid (Logit) Function:** $p = 1 / (1 + e^{-z})$.</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Log Link:** $\ln(\lambda) = \beta X$.</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Deviance:** The GLM version of "Residual Sum of Squares."</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="fu"># Part II: The Modern Complexity {-}</span></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="fu">## 5. The Penalty: Regularization {-}</span></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>**The Narrative:** The Detective gets overconfident and starts seeing conspiracies (Overfitting). We introduce a "Judge" who fines the model for using too many variables.</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Models:**</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Ridge Regression ($L_2$):** Shrinks parameters.</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Lasso Regression ($L_1$):** Selects variables (forces some to zero).</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Elastic Net:** The hybrid approach.</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Theory:**</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Bias-Variance Trade-off:** The fundamental conflict of learning.</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Overfitting:** Memorizing noise vs. learning signal.</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Functions (The Math):**</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Lagrange Multipliers:** Solving constrained optimization.</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**The Penalty Term:** Adding $+\lambda \sum \beta^2$ to the Loss Function.</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Norms:** Euclidean ($L_2$) vs. Manhattan ($L_1$) distance.</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="fu">## 6. The Subjective Return: Bayesian Inference {-}</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>**The Narrative:** We realize the "Penalty" was actually a "Prior Belief." We shift from seeking one True Parameter to mapping the entire distribution of uncertainty.</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Models:**</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Bayesian Linear Regression.**</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Hierarchical/Multilevel Models:** Handling grouped data.</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Theory:**</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Bayes' Theorem:** Updating beliefs with data.</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Priors:** Informative vs. Flat priors.</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Conjugacy:** Mathematical compatibility between Prior and Likelihood.</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Functions (The Math):**</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Posterior Formulation:** $P(\theta|X) \propto P(X|\theta) \cdot P(\theta)$.</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**MCMC (Markov Chain Monte Carlo):** The simulation engine for complex posteriors.</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="fu">## 7. The Invisible Thread: Time Series &amp; Spatial Analysis {-}</span></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>**The Narrative:** We stop assuming data points are independent islands. We acknowledge that today is haunted by yesterday (Time) and location shapes destiny (Space).</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Models:**</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**ARIMA:** Modeling memory in time.</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**SAR / SEM:** Spatial Autoregressive &amp; Spatial Error models.</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Gaussian Processes:** The ultimate model of proximity.</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Theory:**</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Stationarity:** The assumption that rules don't change over time.</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Autocorrelation:** Correlation of a variable with itself.</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Spatial Weights ($W$):** Defining the neighborhood.</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Functions (The Math):**</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Covariance Matrix ($\Sigma$):** Moving from Diagonal (independent) to Dense (correlated).</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**ACF / PACF:** Measuring the "echo" of the past.</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="fu">## 8. The Broken Mirror: Trees &amp; Forests {-}</span></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>**The Narrative:** When the world is too fractured for smooth curves, we break it into shards. We use Decision Trees to split logic and Ensembles (Forests) to stabilize the result.</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Models:**</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**CART (Decision Trees):** The single shard.</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Random Forest:** The Wisdom of Crowds (Bagging).</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Gradient Boosting (XGBoost):** The Learning Student (Boosting).</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Theory:**</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Recursive Partitioning:** Splitting data into homogenous groups.</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Ensemble Learning:** Reducing Variance (Bagging) vs. Reducing Bias (Boosting).</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Gradient Descent in Function Space:** Optimizing predictions step-by-step.</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Functions (The Math):**</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Gini Impurity / Entropy:** Metrics for "purity" in a split.</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="ss">    * </span>**Information Gain:** The reduction in entropy.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>